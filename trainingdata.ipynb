{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  8  8  8  8  8  8  8  7  7  7 19 19 19  4  4  4  4  4  4  4  4  2  2\n",
      "  2  2  2  6  6  6  6  6 10 10 10  5  5  5  5  5  0  0  0  0 20 20 20 20\n",
      " 13 13 13 13 13  9  9  9  9 16 16 16 16 17 17 17 17 17  3  3  3  3 15 15\n",
      " 15 15  1  1  1 18 18 18 18 11 11 11 12 12 12 14 14 14]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "#here we are formatting the data in the json file to be fit as training data\n",
    "\n",
    "embedmodel = SentenceTransformer('nq-distilbert-base-v1')\n",
    "\n",
    "questionsraw = []\n",
    "tagsraw = []\n",
    "qtpairsraw = []\n",
    "\n",
    "with open('intents.json', encoding='utf-8-sig') as file:\n",
    "    data = json.load(file)\n",
    "    for qanda in data['intents']:\n",
    "        t = qanda['tag']\n",
    "        tagsraw.append(t)\n",
    "        for q in qanda['questions']:\n",
    "            questionsraw.append(q)\n",
    "            qtpairsraw.append((q, t)) \n",
    "            \n",
    "tagsraw = sorted(set(tagsonly))\n",
    "\n",
    "questionsencoded = []\n",
    "tagsencoded = []\n",
    "\n",
    "for (q, t) in qtpairsraw:\n",
    "    question = embedmodel.encode(q)\n",
    "    questionsencoded.append(question)\n",
    "    \n",
    "    tag = tagsraw.index(t)\n",
    "    tagsencoded.append(tag)\n",
    "    \n",
    "questionsencoded = np.array(questionsencoded)\n",
    "tagsencoded = np.array(tagsencoded)\n",
    "print(tagsencoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset accessible with data loader so we can iterate over the training data, accessible with indexing\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ChatBot(Dataset):\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(questionsencoded)\n",
    "        self.x_data = questionsencoded\n",
    "        self.y_data = tagsencoded\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, inputsize, hiddensize, outputsize):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(inputsize, hiddensize)\n",
    "        self.l2 = nn.Linear(hiddensize, hiddensize)\n",
    "        self.l3 = nn.Linear(hiddensize, outputsize)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.l3(out)\n",
    "        return out\n",
    "    \n",
    "#hyperparameters\n",
    "dataset = ChatBot()\n",
    "batchsize = 8 #can change this\n",
    "learningrate = 0.001 #can change this\n",
    "epochs = 1000 #can change this\n",
    "inputsize = 768\n",
    "hiddensize = 8\n",
    "outputsize = len(tagsraw)\n",
    "\n",
    "loaddata = DataLoader(dataset = dataset, batch_size = batchsize, shuffle=True, num_workers=0)\n",
    "\n",
    "model = NeuralNet(inputsize, hiddensize, outputsize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100/1000, loss=0.0144\n",
      "epoch 200/1000, loss=0.0055\n",
      "epoch 300/1000, loss=0.0013\n",
      "epoch 400/1000, loss=0.0001\n",
      "epoch 500/1000, loss=0.0002\n",
      "epoch 600/1000, loss=0.0000\n",
      "epoch 700/1000, loss=0.0000\n",
      "epoch 800/1000, loss=0.0000\n",
      "epoch 900/1000, loss=0.0000\n",
      "epoch 1000/1000, loss=0.0000\n",
      "final loss, loss=0.0000\n"
     ]
    }
   ],
   "source": [
    "#loss and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learningrate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for (questionsencoded, tagsencoded) in loaddata:\n",
    "        \n",
    "        #forwarding\n",
    "        outputs = model(questionsencoded)\n",
    "        loss = criterion(outputs, tagsencoded)\n",
    "        \n",
    "        #optimizing\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'epoch {epoch+1}/{epochs}, loss={loss.item():.4f}')\n",
    "        \n",
    "print(f'final loss, loss={loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete, file saved to new.pth\n"
     ]
    }
   ],
   "source": [
    "trainingdata = {\n",
    "    'inputsize': inputsize, \n",
    "    'outputsize': outputsize, \n",
    "    'hiddensize': hiddensize, \n",
    "    'allembeddings': questionsraw, \n",
    "    'alltags': tagsraw,\n",
    "    'state': model.state_dict()\n",
    "}\n",
    "\n",
    "newfile = 'new.pth'\n",
    "torch.save(trainingdata, newfile)\n",
    "\n",
    "print(f'training complete, file saved to {newfile}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (l1): Linear(in_features=768, out_features=8, bias=True)\n",
       "  (l2): Linear(in_features=8, out_features=8, bias=True)\n",
       "  (l3): Linear(in_features=8, out_features=21, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('intents.json', encoding='utf-8-sig') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "training = torch.load(newfile)\n",
    "\n",
    "inputsize = training['inputsize']\n",
    "outpusize = training['outputsize']\n",
    "hiddensize = training['hiddensize']\n",
    "allembeddings = training['allembeddings']\n",
    "alltags = training['alltags']\n",
    "state = training['state']\n",
    "\n",
    "usemodel = NeuralNet(inputsize, hiddensize, outputsize)\n",
    "usemodel.load_state_dict(state)\n",
    "usemodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask me anything about alcohol addiction! Type \"quit\" to exit\n",
      "tensor([13,  6])\n",
      "You: hey\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-210-953bf02afba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpredictedtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtagsencoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "bot = 'AMAAAA'\n",
    "print('Ask me anything about alcohol addiction! Type \"quit\" to exit')\n",
    "\n",
    "print(tagsencoded)\n",
    "while True: \n",
    "    query = input('You: ')\n",
    "    if query == 'quit':\n",
    "        break\n",
    "    else:\n",
    "        query = np.array(embedmodel.encode(query))\n",
    "        query = query.reshape(1, query.shape[0])\n",
    "        query = torch.from_numpy(query)\n",
    "        \n",
    "        output = model(query)\n",
    "        _, predicted = torch.max(output, dim=0)\n",
    "        predictedtag = tagsencoded[predicted.item()]\n",
    "        \n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        probability = probabilities[0][predicted.item()]\n",
    "        \n",
    "        if probability.item() > 0.75:\n",
    "            for qanda in intents['intents']:\n",
    "                if predictedtag == qanda['tag']:\n",
    "                    print(f'{bot}: {qanda[\"answers\"][0]}')\n",
    "        else:\n",
    "            print(f'{bot}: Could you rephrase that? I do not understand...')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
